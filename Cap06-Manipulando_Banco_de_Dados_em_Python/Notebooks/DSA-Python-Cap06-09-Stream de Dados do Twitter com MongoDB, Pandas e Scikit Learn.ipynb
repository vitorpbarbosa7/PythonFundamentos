{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Python Fundamentos - Cap√≠tulo 6</font>\n",
    "\n",
    "## Download: http://github.com/dsacademybr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream de Dados do Twitter com MongoDB, Pandas e Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a Conex√£o com o Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from tweepy) (2.19.1)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from tweepy) (1.11.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vitor\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2018.8.24)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.1.0 requests-oauthlib-1.3.0 tweepy-3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "orange3 3.24.1 requires keyrings.alt, which is not installed.\n",
      "orange3 3.24.1 requires python-louvain>=0.13, which is not installed.\n",
      "orange3 3.24.1 requires serverfiles, which is not installed.\n",
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "orange3 3.24.1 has requirement numpy>=1.16.0, but you'll have numpy 1.15.1 which is incompatible.\n",
      "orange-canvas-core 0.1.11 has requirement pip>=18.0, but you'll have pip 10.0.1 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Instala o pacote tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os m√≥dulos Tweepy, Datetime e Json\n",
    "from tweepy.streaming import StreamListener #Ouvir pelo twitter\n",
    "from tweepy import OAuthHandler #Autentica√ß√£o pelo twitter\n",
    "from tweepy import Stream #Classe de tratamento de streaming do pacote tweepy\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja no manual em pdf como criar sua API no Twitter e configure as suas chaves abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui sua Consumer Key\n",
    "consumer_key = \"ts1VSG249kwQZt3G4gfOYlT9w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui sua Consumer Secret \n",
    "consumer_secret = \"c23ogyLe3kBCMAQ49IST9DEPCdaIirvCkP0WMBh18z4Uq1thzl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui seu Access Token\n",
    "access_token = \"1174700278043611141-S8PkoBl4bEtJyKetkLbtuPt9LU6N93\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione aqui seu Access Token Secret\n",
    "access_token_secret = \"TBmStUq5HrgXUcoH4gYbdVdE0YH9g5WYZLSBLZCIbzrkT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as chaves de autentica√ß√£o\n",
    "#Cria√ß√£o do objeto de autentica√ß√£o a partir da classe importada de autentica√ß√£o \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma classe para capturar os stream de dados do Twitter e \n",
    "# armazenar no MongoDB\n",
    "class MyListener(StreamListener):   \n",
    "    \n",
    "    def __init__(self, time_limit = 60):\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit\n",
    "        self.saveFile = open('streamings.json', 'a')\n",
    "        super(StreamListener, self).__init__()\n",
    "        \n",
    "    def on_data(self, dados):\n",
    "        if (time.time() - self.start_time) < self.limit:\n",
    "#             abcd. = json.loads(dados) #Convers√£o para o formato json para gravar no \n",
    "#             #mongodb\n",
    "            streamings = json.loads(dados)\n",
    "            id_ = streamings[\"id\"]\n",
    "            created_at = streamings[\"created_at\"]\n",
    "            id_str = streamings[\"id_str\"]\n",
    "            text = streamings[\"text\"]\n",
    "            obj = {\"id\":id_,\"created_at\":created_at,\"id_str\":id_str,\"text\":text,}\n",
    "            tweetind = col.insert_one(obj).inserted_id\n",
    "            print (obj)\n",
    "            self.saveFile.write(dados)\n",
    "            self.saveFile.write('\\n')\n",
    "            return True\n",
    "        else:\n",
    "            self.saveFile.close()\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto mylistener\n",
    "mylistener = MyListener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o objeto mystream\n",
    "#Isntanciando o objeto mystream\n",
    "mystream = Stream(auth, listener = MyListener(time_limit = 20))\n",
    "#mystream = Stream(minhas credenciais, meu objeto para ouvir os tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando a Conex√£o com o MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymongo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ee265e7fdbee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Importando do PyMongo o m√≥dulo MongoClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpymongo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymongo'"
     ]
    }
   ],
   "source": [
    "# Importando do PyMongo o m√≥dulo MongoClient\n",
    "from pymongo import MongoClient   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a conex√£o ao MongoDB\n",
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o banco de dados twitterdb\n",
    "db = client.twitterdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a collection \"col\"\n",
    "col = db.tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista de palavras chave para buscar nos Tweets\n",
    "keywords = ['Data Science']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando os Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o filtro e gravando os tweets no MongoDB\n",
    "# mystream.tweepy.Stream(auth = api.auth, listener = StreamListener(time_limit=20))\n",
    "mystream.filter(track=keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --> Pressione o bot√£o Stop na barra de ferramentas para encerrar a captura dos Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultando os Dados no MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5de27752075f4da22e0a62ab'),\n",
       " 'id': 1200778024431562759,\n",
       " 'created_at': 'Sat Nov 30 14:06:05 +0000 2019',\n",
       " 'id_str': '1200778024431562759',\n",
       " 'text': \"RT @Neenar568: OK...it's a toss up~~I'm dying!!!! ü§£üòÇüòÇü§£ https://t.co/CJ02UHvxVY\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando um documento no collection\n",
    "col.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lise de Dados com Pandas e Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataset com dados retornados do MongoDB\n",
    "#Retornar os dados para cada item na cole√ß√£o (Cada item √© um documento)\n",
    "dataset = [{\"created_at\": item[\"created_at\"], \"text\": item[\"text\"],} for item in col.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o m√≥dulo Pandas para trabalhar com datasets em Python\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir do dataset \n",
    "df = pd.DataFrame(dataset) #Cria√ß√£o de um dataframe (objetos com formato de colunas e linhas) a partir do banco de dados dataset presente no mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat Nov 30 14:06:05 +0000 2019</td>\n",
       "      <td>RT @Neenar568: OK...it's a toss up~~I'm dying!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sat Nov 30 14:06:05 +0000 2019</td>\n",
       "      <td>@AdeBARRcode @ravenhaired_sub In essence it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sat Nov 30 14:06:05 +0000 2019</td>\n",
       "      <td>RT @jessphillips: Answer the question you spin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sat Nov 30 14:06:05 +0000 2019</td>\n",
       "      <td>Pahiram netflix acc HAHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Nov 30 14:06:06 +0000 2019</td>\n",
       "      <td>\"our Netflix\" sounds so domestic can you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sat Nov 30 14:06:06 +0000 2019</td>\n",
       "      <td>SAME! Definitely nearing triple digits #renewa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sat Nov 30 14:06:06 +0000 2019</td>\n",
       "      <td>My fucking 123movuee geekin , lemme hold someb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat Nov 30 14:06:07 +0000 2019</td>\n",
       "      <td>RT @travelkaan: ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° ‡∏ñ‡∏π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sat Nov 30 14:06:07 +0000 2019</td>\n",
       "      <td>Ultimatoüò±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sat Nov 30 14:06:07 +0000 2019</td>\n",
       "      <td>@Mr_Barnett10 8 hours of netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sat Nov 30 14:06:08 +0000 2019</td>\n",
       "      <td>RT @RBReich: What do these corporations have i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sat Nov 30 14:06:08 +0000 2019</td>\n",
       "      <td>RT @gabalexa: can someone explain why Netflix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sat Nov 30 14:06:08 +0000 2019</td>\n",
       "      <td>RT @vinyl_tackey: „Äé„Ç´„É≥„Éï„Éº„Éª„É®„Ç¨„Äè„ÅØNetflix„ÅßÈÖç‰ø°„Åã„Äú„Å®ÊÄù„Å£„Å¶„ÅÑ„Åü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sat Nov 30 14:06:08 +0000 2019</td>\n",
       "      <td>RT @gemma_st_cloud: Wouldn't it be wonderful t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat Nov 30 14:06:09 +0000 2019</td>\n",
       "      <td>RT @DanielJJonesUS: Re-Print of the Senate ‚ÄúTo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sat Nov 30 14:06:10 +0000 2019</td>\n",
       "      <td>RT @Komod0o: 9000 abonn√©s üòù √ßa m‚Äôa donn√© envie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sat Nov 30 14:06:10 +0000 2019</td>\n",
       "      <td>RT @fruitsvsten: And he had that really proud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sat Nov 30 14:06:10 +0000 2019</td>\n",
       "      <td>RT @shawntvamps: n√£o desmerecendo outras s√©rie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sat Nov 30 14:06:10 +0000 2019</td>\n",
       "      <td>This is such an amaizing show that must contin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sat Nov 30 14:06:11 +0000 2019</td>\n",
       "      <td>RT @pppisut: Met A Space Pod ‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡πÇ‡∏®‡∏Å\\n‡∏≠‡∏¢‡∏π‡πà‡∏î‡∏µ‡πÜ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sat Nov 30 14:06:11 +0000 2019</td>\n",
       "      <td>12 years today I was producing my uni professo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sat Nov 30 14:06:11 +0000 2019</td>\n",
       "      <td>RT @paulwaugh: Now @BorisJohnson really is in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sat Nov 30 14:06:11 +0000 2019</td>\n",
       "      <td>RT @yajpeg: actually shocked by the backlash t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sat Nov 30 14:06:11 +0000 2019</td>\n",
       "      <td>RT @BASE_JUALAN: sell JUAL APP PREMIUM, 100% L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sat Nov 30 14:06:11 +0000 2019</td>\n",
       "      <td>RT @iispace64: So disney plus doesn‚Äôt have\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sat Nov 30 14:06:13 +0000 2019</td>\n",
       "      <td>@lxrelaaa @iMatxlda Now the real question is ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sat Nov 30 14:06:13 +0000 2019</td>\n",
       "      <td>@leonardotupi Quando chegar o Disney Plus aqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sat Nov 30 14:06:14 +0000 2019</td>\n",
       "      <td>RT @alxrgs: ENFIN !!!! https://t.co/HC9OGuyKBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sat Nov 30 14:06:14 +0000 2019</td>\n",
       "      <td>i wanna finish these reqs na so i can swim, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sat Nov 30 14:06:14 +0000 2019</td>\n",
       "      <td>RT @RBReich: What do these corporations have i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sat Nov 30 14:06:16 +0000 2019</td>\n",
       "      <td>RT @travelkaan: ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° ‡∏ñ‡∏π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sat Nov 30 14:06:16 +0000 2019</td>\n",
       "      <td>RT @TheNightCircusx: I cry whenever I see anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Sat Nov 30 14:06:16 +0000 2019</td>\n",
       "      <td>870K HQ Combo (Spotify,Deezer,Crunchy,Netflix,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sat Nov 30 14:06:16 +0000 2019</td>\n",
       "      <td>‡∏´‡∏≤‡∏£ Viu Premium \\n‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å‡∏°‡∏≤‡∏Å‡∏Å‡∏Å‡∏Å ‡πÅ‡∏°‡πà‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡πá‡∏ß‡∏¢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sat Nov 30 14:06:17 +0000 2019</td>\n",
       "      <td>T√° quando q sa√≠ o exo no knowing brothers na N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sat Nov 30 14:06:17 +0000 2019</td>\n",
       "      <td>RT @fruitsvsten: And he had that really proud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Sat Nov 30 14:06:17 +0000 2019</td>\n",
       "      <td>RT @plausible4me: And I paid a ton of taxes.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Sat Nov 30 14:06:18 +0000 2019</td>\n",
       "      <td>New Episodes of The Proud Family Are Headed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sat Nov 30 14:06:18 +0000 2019</td>\n",
       "      <td>RT @CadenaDeSeguido: NOS SEGUIMOS TODOS \\n\\nüÉèR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Sat Nov 30 14:06:19 +0000 2019</td>\n",
       "      <td>RT @Channel4News: Sir David Attenborough says ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Sat Nov 30 14:06:19 +0000 2019</td>\n",
       "      <td>@Netflixhelps @33Arduc @e73FxFSDzOGwsi7 @netfl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sat Nov 30 14:06:19 +0000 2019</td>\n",
       "      <td>RT @IGN: Prime Stranding. https://t.co/bDto2es1fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sat Nov 30 14:06:20 +0000 2019</td>\n",
       "      <td>RT @GossipRoomOff: Netflix d√©veloppe actuellem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sat Nov 30 14:06:20 +0000 2019</td>\n",
       "      <td>Porra vai demorar pra caralho pra esse epis√≥di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sat Nov 30 14:06:20 +0000 2019</td>\n",
       "      <td>RT @dunerfors: I created a viewing guide for e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Sat Nov 30 14:06:20 +0000 2019</td>\n",
       "      <td>RT @MovNaranja3: Sab√≠a que transportadores no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Sat Nov 30 14:06:21 +0000 2019</td>\n",
       "      <td>RT @shirbertluv: WE ARE DOING THIS FOR HER #re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @EMahmoudSoliman: ÿ™ÿ≠ÿ∞Ÿäÿ± ŸáÿßŸÖ\\nÿ±ÿ≥ÿßÿ¶ŸÑ ÿ®ÿ±ŸäÿØ ÿ•ŸÑŸÉ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>@Belleme_ ‡∏ó‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤netflix‡∏î‡∏π‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @_sandraribeiro_: Combinem isto comigo, jur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @GossipRoomOff: Netflix d√©veloppe actuellem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @fatboy22642: Lol..Ok I‚Äôm dying over here!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @CCNews__: Sab√≠a que pasar tanto tiempo vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @anneskindred: still lowkey think netflix w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>RT @nicktolhurst: Boris Johnson uses his condo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Sat Nov 30 14:06:22 +0000 2019</td>\n",
       "      <td>eu n√£o acredito que revenge entrou na globo pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Sat Nov 30 14:06:23 +0000 2019</td>\n",
       "      <td>RT @Desiiah: Bon, j‚Äô√©cris la liste des films q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Sat Nov 30 14:06:23 +0000 2019</td>\n",
       "      <td>13 Reasons Why: Season 3 | Official Trailer | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Sat Nov 30 14:06:23 +0000 2019</td>\n",
       "      <td>RT @ColoraSeller: GO INSTALER PI NETWORK ET ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Sat Nov 30 14:06:23 +0000 2019</td>\n",
       "      <td>„ÅäÂÆ∂„ÅÆ„ÉÜ„É¨„ÉìÁ¢∫Ë™ç„Åó„Åü„ÇâHDMIÔºü„ÅÆÁ©¥Á©∫„ÅÑ„Å¶„Åü„Åã„ÇâHDMI„Ç±„Éº„Éñ„É´Ôºü„Å®„ÅÇ„ÅÆÊ©üÊ¢∞ÔºüË≤∑„Å£„Åü„Çâ„ÉÜ„É¨„Éì...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Sat Nov 30 14:06:05 +0000 2019   \n",
       "1   Sat Nov 30 14:06:05 +0000 2019   \n",
       "2   Sat Nov 30 14:06:05 +0000 2019   \n",
       "3   Sat Nov 30 14:06:05 +0000 2019   \n",
       "4   Sat Nov 30 14:06:06 +0000 2019   \n",
       "5   Sat Nov 30 14:06:06 +0000 2019   \n",
       "6   Sat Nov 30 14:06:06 +0000 2019   \n",
       "7   Sat Nov 30 14:06:07 +0000 2019   \n",
       "8   Sat Nov 30 14:06:07 +0000 2019   \n",
       "9   Sat Nov 30 14:06:07 +0000 2019   \n",
       "10  Sat Nov 30 14:06:08 +0000 2019   \n",
       "11  Sat Nov 30 14:06:08 +0000 2019   \n",
       "12  Sat Nov 30 14:06:08 +0000 2019   \n",
       "13  Sat Nov 30 14:06:08 +0000 2019   \n",
       "14  Sat Nov 30 14:06:09 +0000 2019   \n",
       "15  Sat Nov 30 14:06:10 +0000 2019   \n",
       "16  Sat Nov 30 14:06:10 +0000 2019   \n",
       "17  Sat Nov 30 14:06:10 +0000 2019   \n",
       "18  Sat Nov 30 14:06:10 +0000 2019   \n",
       "19  Sat Nov 30 14:06:11 +0000 2019   \n",
       "20  Sat Nov 30 14:06:11 +0000 2019   \n",
       "21  Sat Nov 30 14:06:11 +0000 2019   \n",
       "22  Sat Nov 30 14:06:11 +0000 2019   \n",
       "23  Sat Nov 30 14:06:11 +0000 2019   \n",
       "24  Sat Nov 30 14:06:11 +0000 2019   \n",
       "25  Sat Nov 30 14:06:13 +0000 2019   \n",
       "26  Sat Nov 30 14:06:13 +0000 2019   \n",
       "27  Sat Nov 30 14:06:14 +0000 2019   \n",
       "28  Sat Nov 30 14:06:14 +0000 2019   \n",
       "29  Sat Nov 30 14:06:14 +0000 2019   \n",
       "..                             ...   \n",
       "35  Sat Nov 30 14:06:16 +0000 2019   \n",
       "36  Sat Nov 30 14:06:16 +0000 2019   \n",
       "37  Sat Nov 30 14:06:16 +0000 2019   \n",
       "38  Sat Nov 30 14:06:16 +0000 2019   \n",
       "39  Sat Nov 30 14:06:17 +0000 2019   \n",
       "40  Sat Nov 30 14:06:17 +0000 2019   \n",
       "41  Sat Nov 30 14:06:17 +0000 2019   \n",
       "42  Sat Nov 30 14:06:18 +0000 2019   \n",
       "43  Sat Nov 30 14:06:18 +0000 2019   \n",
       "44  Sat Nov 30 14:06:19 +0000 2019   \n",
       "45  Sat Nov 30 14:06:19 +0000 2019   \n",
       "46  Sat Nov 30 14:06:19 +0000 2019   \n",
       "47  Sat Nov 30 14:06:20 +0000 2019   \n",
       "48  Sat Nov 30 14:06:20 +0000 2019   \n",
       "49  Sat Nov 30 14:06:20 +0000 2019   \n",
       "50  Sat Nov 30 14:06:20 +0000 2019   \n",
       "51  Sat Nov 30 14:06:21 +0000 2019   \n",
       "52  Sat Nov 30 14:06:22 +0000 2019   \n",
       "53  Sat Nov 30 14:06:22 +0000 2019   \n",
       "54  Sat Nov 30 14:06:22 +0000 2019   \n",
       "55  Sat Nov 30 14:06:22 +0000 2019   \n",
       "56  Sat Nov 30 14:06:22 +0000 2019   \n",
       "57  Sat Nov 30 14:06:22 +0000 2019   \n",
       "58  Sat Nov 30 14:06:22 +0000 2019   \n",
       "59  Sat Nov 30 14:06:22 +0000 2019   \n",
       "60  Sat Nov 30 14:06:22 +0000 2019   \n",
       "61  Sat Nov 30 14:06:23 +0000 2019   \n",
       "62  Sat Nov 30 14:06:23 +0000 2019   \n",
       "63  Sat Nov 30 14:06:23 +0000 2019   \n",
       "64  Sat Nov 30 14:06:23 +0000 2019   \n",
       "\n",
       "                                                 text  \n",
       "0   RT @Neenar568: OK...it's a toss up~~I'm dying!...  \n",
       "1   @AdeBARRcode @ravenhaired_sub In essence it is...  \n",
       "2   RT @jessphillips: Answer the question you spin...  \n",
       "3                            Pahiram netflix acc HAHA  \n",
       "4           \"our Netflix\" sounds so domestic can you.  \n",
       "5   SAME! Definitely nearing triple digits #renewa...  \n",
       "6   My fucking 123movuee geekin , lemme hold someb...  \n",
       "7   RT @travelkaan: ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° ‡∏ñ‡∏π...  \n",
       "8                                           Ultimatoüò±  \n",
       "9                 @Mr_Barnett10 8 hours of netflix...  \n",
       "10  RT @RBReich: What do these corporations have i...  \n",
       "11  RT @gabalexa: can someone explain why Netflix ...  \n",
       "12  RT @vinyl_tackey: „Äé„Ç´„É≥„Éï„Éº„Éª„É®„Ç¨„Äè„ÅØNetflix„ÅßÈÖç‰ø°„Åã„Äú„Å®ÊÄù„Å£„Å¶„ÅÑ„Åü...  \n",
       "13  RT @gemma_st_cloud: Wouldn't it be wonderful t...  \n",
       "14  RT @DanielJJonesUS: Re-Print of the Senate ‚ÄúTo...  \n",
       "15  RT @Komod0o: 9000 abonn√©s üòù √ßa m‚Äôa donn√© envie...  \n",
       "16  RT @fruitsvsten: And he had that really proud ...  \n",
       "17  RT @shawntvamps: n√£o desmerecendo outras s√©rie...  \n",
       "18  This is such an amaizing show that must contin...  \n",
       "19  RT @pppisut: Met A Space Pod ‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡πÇ‡∏®‡∏Å\\n‡∏≠‡∏¢‡∏π‡πà‡∏î‡∏µ‡πÜ...  \n",
       "20  12 years today I was producing my uni professo...  \n",
       "21  RT @paulwaugh: Now @BorisJohnson really is in ...  \n",
       "22  RT @yajpeg: actually shocked by the backlash t...  \n",
       "23  RT @BASE_JUALAN: sell JUAL APP PREMIUM, 100% L...  \n",
       "24  RT @iispace64: So disney plus doesn‚Äôt have\\n\\n...  \n",
       "25  @lxrelaaa @iMatxlda Now the real question is ....  \n",
       "26  @leonardotupi Quando chegar o Disney Plus aqui...  \n",
       "27     RT @alxrgs: ENFIN !!!! https://t.co/HC9OGuyKBO  \n",
       "28  i wanna finish these reqs na so i can swim, ne...  \n",
       "29  RT @RBReich: What do these corporations have i...  \n",
       "..                                                ...  \n",
       "35  RT @travelkaan: ‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡∏°‡∏≤‡∏Å ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° ‡∏ñ‡∏π...  \n",
       "36  RT @TheNightCircusx: I cry whenever I see anyt...  \n",
       "37  870K HQ Combo (Spotify,Deezer,Crunchy,Netflix,...  \n",
       "38  ‡∏´‡∏≤‡∏£ Viu Premium \\n‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å‡∏°‡∏≤‡∏Å‡∏Å‡∏Å‡∏Å ‡πÅ‡∏°‡πà‡∏Ñ‡πâ‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡πá‡∏ß‡∏¢...  \n",
       "39  T√° quando q sa√≠ o exo no knowing brothers na N...  \n",
       "40  RT @fruitsvsten: And he had that really proud ...  \n",
       "41  RT @plausible4me: And I paid a ton of taxes.  ...  \n",
       "42  New Episodes of The Proud Family Are Headed to...  \n",
       "43  RT @CadenaDeSeguido: NOS SEGUIMOS TODOS \\n\\nüÉèR...  \n",
       "44  RT @Channel4News: Sir David Attenborough says ...  \n",
       "45  @Netflixhelps @33Arduc @e73FxFSDzOGwsi7 @netfl...  \n",
       "46  RT @IGN: Prime Stranding. https://t.co/bDto2es1fa  \n",
       "47  RT @GossipRoomOff: Netflix d√©veloppe actuellem...  \n",
       "48  Porra vai demorar pra caralho pra esse epis√≥di...  \n",
       "49  RT @dunerfors: I created a viewing guide for e...  \n",
       "50  RT @MovNaranja3: Sab√≠a que transportadores no ...  \n",
       "51  RT @shirbertluv: WE ARE DOING THIS FOR HER #re...  \n",
       "52  RT @EMahmoudSoliman: ÿ™ÿ≠ÿ∞Ÿäÿ± ŸáÿßŸÖ\\nÿ±ÿ≥ÿßÿ¶ŸÑ ÿ®ÿ±ŸäÿØ ÿ•ŸÑŸÉ...  \n",
       "53  @Belleme_ ‡∏ó‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤netflix‡∏î‡∏π‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±...  \n",
       "54  RT @_sandraribeiro_: Combinem isto comigo, jur...  \n",
       "55  RT @GossipRoomOff: Netflix d√©veloppe actuellem...  \n",
       "56  RT @fatboy22642: Lol..Ok I‚Äôm dying over here!!...  \n",
       "57  RT @CCNews__: Sab√≠a que pasar tanto tiempo vie...  \n",
       "58  RT @anneskindred: still lowkey think netflix w...  \n",
       "59  RT @nicktolhurst: Boris Johnson uses his condo...  \n",
       "60  eu n√£o acredito que revenge entrou na globo pl...  \n",
       "61  RT @Desiiah: Bon, j‚Äô√©cris la liste des films q...  \n",
       "62  13 Reasons Why: Season 3 | Official Trailer | ...  \n",
       "63  RT @ColoraSeller: GO INSTALER PI NETWORK ET ME...  \n",
       "64  „ÅäÂÆ∂„ÅÆ„ÉÜ„É¨„ÉìÁ¢∫Ë™ç„Åó„Åü„ÇâHDMIÔºü„ÅÆÁ©¥Á©∫„ÅÑ„Å¶„Åü„Åã„ÇâHDMI„Ç±„Éº„Éñ„É´Ôºü„Å®„ÅÇ„ÅÆÊ©üÊ¢∞ÔºüË≤∑„Å£„Åü„Çâ„ÉÜ„É¨„Éì...  \n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo o dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o m√≥dulo Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o m√©todo CountVectorizer para criar uma matriz de documentos\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>netflix</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>co</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>we</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>of</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>de</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>for</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>que</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>na</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>plus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>my</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>this</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jual</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>up</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>so</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>are</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>on</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>now</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>like</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>northwoodenter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cbc</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>proud</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>les</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>me</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>what</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>just</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>his</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>renewannewithane</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>prime</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>can</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>un</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>that</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>was</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>long</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>et</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>you</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>disney</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>do</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>have</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pra</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>amazon</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  count\n",
       "0                 rt     40\n",
       "1            netflix     29\n",
       "2              https     23\n",
       "3                 co     22\n",
       "4                the     17\n",
       "5                and     11\n",
       "6                 is      9\n",
       "7                 to      9\n",
       "8                 it      8\n",
       "9                 we      7\n",
       "10                of      7\n",
       "11                he      6\n",
       "12                de      6\n",
       "13                in      6\n",
       "14               for      6\n",
       "15               que      5\n",
       "16                na      5\n",
       "17              plus      5\n",
       "18                my      5\n",
       "19              this      5\n",
       "20              jual      5\n",
       "21                up      4\n",
       "22                so      4\n",
       "23               are      4\n",
       "24                on      4\n",
       "25               now      4\n",
       "26              like      4\n",
       "27    northwoodenter      4\n",
       "28               cbc      4\n",
       "29             proud      4\n",
       "30               les      4\n",
       "31                me      4\n",
       "32              what      4\n",
       "33              just      4\n",
       "34               his      4\n",
       "35  renewannewithane      4\n",
       "36             prime      4\n",
       "37               can      3\n",
       "38                un      3\n",
       "39                no      3\n",
       "40              that      3\n",
       "41               was      3\n",
       "42              long      3\n",
       "43                et      3\n",
       "44               you      3\n",
       "45            disney      3\n",
       "46                do      3\n",
       "47              have      3\n",
       "48               pra      3\n",
       "49            amazon      3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contando o n√∫mero de ocorr√™ncias das principais palavras em nosso dataset\n",
    "word_count = pd.DataFrame(cv.get_feature_names(), columns=[\"word\"])\n",
    "word_count[\"count\"] = count_matrix.sum(axis=0).tolist()[0]\n",
    "word_count = word_count.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "word_count[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
